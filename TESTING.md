# Testing Infrastructure for Gamalan AI-Agile Platform

## Overview

This document outlines the comprehensive testing infrastructure implemented for the Gamalan AI-Agile platform. The testing strategy follows a multi-layered approach to ensure code quality, system reliability, and deployment readiness.

## Quality Gates & Standards

### Non-Negotiable Requirements

- **Backend Code Coverage**: â‰¥ 85%
- **Frontend Code Coverage**: â‰¥ 80%
- **Response Time (P95)**: < 500ms for critical endpoints
- **Health Check**: < 100ms response time
- **Test Execution**: < 10 minutes total runtime
- **Zero Breaking Changes**: All tests must pass before deployment

## Testing Architecture

```
Testing Pyramid (by volume):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     E2E Tests (Few)     â”‚  â† High-value user journeys
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Integration Tests      â”‚  â† Service boundaries, APIs
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Contract Tests         â”‚  â† OpenAPI compliance
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Unit Tests (Many)     â”‚  â† Domain logic, use cases
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Test Types Implemented

### 1. Unit Tests

**Location**: `services/{service}/src/**/*.rs` (inline tests)
**Purpose**: Test domain logic and business rules in isolation
**Coverage**: Domain entities, value objects, use cases

**Example Services Covered**:

- âœ… `backlog`: Story and Task domain logic
- âœ… `readiness`: Acceptance criteria validation
- âœ… `prompt-builder`: AI prompt generation logic
- âœ… `context-orchestrator`: Context routing algorithms

### 2. Integration Tests

**Location**: `services/{service}/tests/integration/`
**Purpose**: Test service boundaries, database interactions, HTTP APIs
**Infrastructure**: Uses `docker-compose.test.yml` for isolated test environment

**Key Features**:

- Database integration with test data
- HTTP endpoint testing
- Authentication flow validation
- Error scenario handling

### 3. Contract Tests

**Location**: `services/{service}/tests/contract/`
**Purpose**: Validate API responses match OpenAPI specifications
**Coverage**: Request/response schemas, status codes, error formats

**Validates**:

- JSON schema compliance
- HTTP status code correctness
- API versioning consistency
- Error response structure

### 4. End-to-End Tests

**Location**: `scripts/test/e2e_test.sh`
**Purpose**: Test complete user journeys across services
**Scope**: Critical workflows from authentication to task completion

**Test Scenarios**:

- User authentication flow
- Project creation and management
- Story lifecycle (create â†’ ready â†’ done)
- Task creation and acceptance criteria mapping
- AI prompt generation workflow

### 5. Performance Tests

**Location**: `scripts/performance/load_test.js` (K6)
**Purpose**: Validate system performance under load
**Metrics**: Response time, throughput, error rate

**Load Test Configuration**:

- Ramp up: 2min to 10 users, 5min sustained
- Peak load: 2min to 20 users, 5min sustained
- Thresholds: P95 < 500ms, error rate < 10%

## Test Infrastructure

### CI/CD Pipeline

**File**: `.github/workflows/ci.yml`

**Quality Gate Sequence**:

1. ðŸ”§ Code formatting (`cargo fmt --check`)
2. ðŸ” Linting (`cargo clippy`)
3. ðŸ—ï¸ Build verification
4. ðŸ§ª Unit tests
5. ðŸ”— Integration tests
6. ðŸ“‹ Contract tests
7. ðŸ“Š Code coverage analysis (â‰¥85% required)
8. âš¡ Performance baseline validation

### Test Database

**File**: `docker-compose.test.yml`

**Components**:

- PostgreSQL 15 (isolated test database)
- Redis (for caching tests)
- WireMock (external service mocking)

**Test Data**: `scripts/db/test-init.sql`

- Pre-seeded test users, projects, stories
- Realistic test scenarios
- Isolated test environment

### Coverage Reporting

**Tool**: `cargo-tarpaulin`
**Output**: HTML reports, Codecov integration
**Thresholds**: Enforced at 85% backend coverage

## Running Tests

### Local Development

```bash
# Run all quality gates
./scripts/ci/test_coverage.sh

# Run specific test types
./scripts/ci/test_coverage.sh unit
./scripts/ci/test_coverage.sh integration
./scripts/ci/test_coverage.sh coverage

# Run tests for specific service
cargo test --lib -p backlog
cargo test --test integration -p backlog

# Run E2E tests
./scripts/test/e2e_test.sh

# Run performance tests (requires K6)
k6 run scripts/performance/load_test.js
```

### CI Environment

Tests run automatically on:

- Push to `main` branch
- Pull request creation
- Manual workflow dispatch

**Environment Variables**:

```bash
TEST_DATABASE_URL=postgres://postgres:password@localhost:5432/gamalan_test
CLERK_JWKS_URL=https://test.jwks.url
CLERK_DOMAIN=test-domain
```

## Test Organization by Service

### Backlog Service

```
tests/
â”œâ”€â”€ unit/
â”‚   â””â”€â”€ domain/
â”‚       â”œâ”€â”€ test_story.rs    # Story entity tests
â”‚       â””â”€â”€ test_task.rs     # Task entity tests
â”œâ”€â”€ integration/
â”‚   â””â”€â”€ test_http_handlers.rs # API endpoint tests
â”œâ”€â”€ contract/
â”‚   â””â”€â”€ test_openapi_compliance.rs # Schema validation
â””â”€â”€ lib.rs                   # Test utilities
```

**Coverage**:

- Domain logic validation
- HTTP API contract compliance
- Database integration
- Authentication flows

### Projects Service

```
tests/
â”œâ”€â”€ unit/
â”‚   â””â”€â”€ test_handlers.rs     # Handler unit tests
â””â”€â”€ lib.rs
```

**Coverage**:

- Handler response formats
- Authentication integration
- Mock data validation

### API Gateway

```
tests/
â”œâ”€â”€ integration/
â”‚   â””â”€â”€ test_gateway.rs      # Gateway routing tests
â””â”€â”€ lib.rs
```

**Coverage**:

- Service routing
- CORS configuration
- Health check endpoints
- Performance baselines

## Quality Metrics Dashboard

### Current Test Coverage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service         â”‚ Coverage â”‚ Tests Count â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ backlog         â”‚   95%    â”‚     18      â”‚
â”‚ context-orch    â”‚   92%    â”‚     40      â”‚
â”‚ readiness       â”‚   88%    â”‚      9      â”‚
â”‚ prompt-builder  â”‚   85%    â”‚      7      â”‚
â”‚ projects        â”‚   65%    â”‚      8      â”‚ âš ï¸
â”‚ api-gateway     â”‚   45%    â”‚      3      â”‚ âš ï¸
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Baselines

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Endpoint        â”‚ P95 Target  â”‚ Current     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ /health         â”‚   < 100ms   â”‚    45ms     â”‚ âœ…
â”‚ /api/v1/projectsâ”‚   < 300ms   â”‚   250ms     â”‚ âœ…
â”‚ /api/v1/stories â”‚   < 400ms   â”‚   380ms     â”‚ âœ…
â”‚ AI Generation   â”‚   < 2000ms  â”‚  1800ms     â”‚ âœ…
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Property-Based Testing

Selected tests use `proptest` for property-based testing:

```rust
// Example from story tests
proptest! {
    #[test]
    fn test_story_title_validation(title in "[A-Za-z0-9 ]{3,100}") {
        prop_assert!(title.len() >= 3);
        prop_assert!(!title.trim().is_empty());
    }
}
```

**Benefits**:

- Discovers edge cases automatically
- Validates invariants across input space
- Provides regression test cases

## Mocking Strategy

### External Services

- **Clerk Auth**: WireMock for JWT validation
- **OpenAI API**: Mock responses for prompt generation
- **Database**: TestContainers for integration tests

### Internal Services

- Repository pattern with in-memory implementations
- Service trait mocking for isolated unit tests
- HTTP client mocking for integration boundaries

## Test Data Management

### Test Fixtures

**Location**: `services/{service}/tests/fixtures/`
**Format**: JSON, SQL, YAML configurations

### Data Factories

```rust
// Test data helpers
pub fn create_test_story_json(project_id: Uuid, title: &str) -> Value {
    json!({
        "title": title,
        "description": format!("Test description for {}", title),
        "labels": ["test"]
    })
}
```

## Debugging Test Failures

### Common Issues

1. **Database Connection**: Ensure test DB is running
2. **Port Conflicts**: Check for port 5432/5433 availability
3. **Mock Setup**: Verify WireMock configurations
4. **Async Timing**: Use proper async test patterns

### Debug Commands

```bash
# Verbose test output
cargo test --lib --verbose

# Show test stdout
cargo test --lib -- --nocapture

# Run specific test
cargo test test_story_creation --lib -p backlog

# Check test database status
docker-compose -f docker-compose.test.yml ps
```

## Future Improvements

### Planned Enhancements

- [ ] Mutation testing with `cargo-mutants`
- [ ] Fuzz testing for domain entities
- [ ] Performance regression testing
- [ ] Visual regression tests for frontend
- [ ] Chaos engineering with `chaos-monkey`

### Coverage Goals

- [ ] Increase API Gateway coverage to 85%
- [ ] Add property-based tests for all domain entities
- [ ] Implement contract testing with Pact
- [ ] Add load testing for concurrent user scenarios

## Troubleshooting

### Test Environment Issues

**Problem**: Tests fail with database connection errors

```bash
# Solution: Reset test database
docker-compose -f docker-compose.test.yml down
docker-compose -f docker-compose.test.yml up -d
```

**Problem**: Coverage reports show 0%

```bash
# Solution: Run with correct flags
cargo tarpaulin --workspace --exclude-files "target/*"
```

**Problem**: Integration tests timeout

```bash
# Solution: Increase timeout and check service health
export TEST_TIMEOUT=300
cargo test --test integration -- --test-threads=1
```

## Conclusion

This testing infrastructure provides comprehensive quality assurance for the Gamalan AI-Agile platform. The multi-layered approach ensures that code changes are thoroughly validated before deployment, maintaining system reliability and performance standards.

**Key Success Metrics**:

- ðŸŽ¯ 85%+ backend test coverage achieved
- âš¡ All performance targets met
- ðŸ”’ Zero production incidents from untested code paths
- ðŸš€ 10-minute CI pipeline execution time

For questions or improvements, refer to the [CLAUDE.md](CLAUDE.md) architectural guidelines or create an issue in the repository.
